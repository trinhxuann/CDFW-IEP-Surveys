---
title: Interagency Ecological Program San Francisco Estuary Smelt Larval Survey (SLS)
  Metadata
output:
  pdf_document:
    toc: yes
    toc_depth: '2'
  html_document:
    toc: yes
    toc_float:
      toc_collapsed: yes
    toc_depth: 2
    number_sections: no
    theme: lumen
editor_options: 
  chunk_output_type: console
---

<!-- Changing things to be at least 12 pt font -->
<style type="text/css">
  body{
  font-size: 12pt;
}
</style>

```{r setup, include=FALSE}
# Loading libraries

library(kableExtra)
library(dplyr)
library(ggplot2)
library(leaflet)
library(mapview)

options(scipen = 999, width = 80)

knitr::opts_chunk$set(dpi=320, fig.width=18, fig.height=14, warning=FALSE, message=F, 
                      dev.args = list(pointsize = 13), echo = F)

makeKable <- function(df, caption = NULL, height = NULL) {

  table <- kbl(df, caption = caption, booktabs = T) %>%
    kable_styling(latex_options = "striped", )
  # kable_classic(full_width = T, html_font = "Cambria", "striped")

  # if (!is.null(height)) {
  #   height <- paste0(height, "px")
  # 
  #   table <- scroll_box(table, width = width, height = height)
  # }
  table
}

# Joined SLS dataset
SLS <- read.csv(file.path("SLS", "SLS.csv"))
```

## Study Management
**IEP Study Name:** Smelt Larval Survey (SLS)

**Program element:** 096

**Agency:** Department of Fish and Wildlife, Bay Delta Region (R3)

**Office Location:**

Address: 2109 Arch Airport Rd Suite 100, Stockton, CA 95206

Phone: (209) 234-3420

**Program manager:** James Hobbs, [James.Hobbs@Wildlife.ca.gov](mailto:James.Hobbs@Wildlife.ca.gov)

**Project leads:** Vanessa Mora, [Vanessa.Mora@Wildlife.ca.gov](mailto:Vanessa.Mora@Wildlife.ca.gov)

  Jennifer Oceguera Zavala, [Jennifer.Oceguerazavala@wildlife.ca.gov](mailto:Jennifer.Oceguerazavala@wildlife.ca.gov)

  Jessica A. Jimenez, [Jessica.Jimenez@wildlife.ca.gov](mailto:Jessica.Jimenez@wildlife.ca.gov)

## Study Overview

**Purpose/Objective:** Monitor and provide information on larval Longfin Smelt (*Spirinchus thaleichthys*) abundance and distribution in the upper San Francisco Estuary. Conduct larval fish surveys to determine the timing, distribution, and abundance of Longfin Smelt larvae. Help estimate larval Longfin Smelt fish losses and determine the magnitude of entrainment of larval Longfin Smelt at the CVP (Central Valley Project) and SWP (State Water Project) intakes.

**Data collected:** Surface water temperature (°C), surface and bottom electro-conductivity (EC, $\mu$S/cm, normalized at 25 °C), Secchi depth (cm), surface water turbidity (NTU, FNU), water volume (m$^3$), tidal stage, start and end tow coordinates (DMS). Fish are identified to the lowest possible taxonomic level, enumerated, and measured (mm) to fork length when possible or total length when the fork in the caudal fin is not present.

**Geographic range of work:** Lower Napa River to the city of Napa, San Pablo Bay upstream throughout Suisun Bay; San Joaquin River to Stockton, Old and Middle Rivers in the south Delta to West Canal; Sacramento River to Rio Vista; Cache Slough from Rio Vista to Shag Slough; 1 station at the mouth of the Sacramento Deep-water Ship Channel.

```{r, overall map, echo = F, results='asis'}
specialStations <- data.frame(Station = c(716, 809, 812, 815, 901, 902, 906, 910, 912, 914, 915, 918, 919, 340, 342, 343, 344, 345, 346, 347, 348, 349, 404, 401, 338, 329, 335, 328, 327, 315, 306, 308, 311, 322, 330, 323, 336),
                              Status = c("Barker ITP Station", rep("SWP ITP Criteria Stations", 12), rep("Napa River Stations", 9), rep("San Pablo Expansion Stations", 15)))

# To color the stations on the map accordingly
# pal <- colorFactor(c("#e41a1c", "#3D8B3A", "#984ea3"), domain = c(specialStations$Status, "SLS Stations"))
pal <- colorFactor(c("#32CD32", "#EE0000FF", "#008B45FF","#F87217" , "#2B1B17" ), domain = c(specialStations$Status, "SLS Stations"))

mapDF <- read.csv(file.path("SLS", "Station_Lookup.csv")) %>%
            mutate(LatD = sapply(strsplit(.$Lat, "\\s"), "[", 1),
                     LatM = sapply(strsplit(.$Lat, "\\s"), "[", 2),
                     LatS = sapply(strsplit(.$Lat, "\\s"), "[", 3),
                     LonD = sapply(strsplit(.$Long, "\\s"), "[", 1),
                     LonM = sapply(strsplit(.$Long, "\\s"), "[", 2),
                     LonS = sapply(strsplit(.$Long, "\\s"), "[", 3),
                     across(c(LatD, LatM, LatS, LonD, LonM, LonS), as.numeric)) %>%
              transmute(Station,
                        Latitude = LatD + LatM/60 + LatS/3600,
                        Longitude = -(LonD + LonM/60 + LonS/3600),
                        group = "TheoreticalCoords") %>%
            left_join(specialStations, by = "Station") %>%
            mutate(Status = factor(ifelse(is.na(Status), "SLS Stations", Status),
                                   levels = c("SLS Stations", "Barker ITP Station", "SWP ITP Criteria Stations", "Napa River Stations", "San Pablo Expansion Stations")),
                   offsetX = case_when(Station %in% 723 ~ c(-22),
                                  TRUE ~ c(22)),
           offsetY = case_when(Station %in% 723 ~ c(0),
                                  TRUE ~ c(0)))

m <- leaflet(mapDF) %>%
    addProviderTiles(providers$CartoDB.VoyagerNoLabels)

stationList <- mapDF %>%
    split(., .$Station)

names(stationList) %>%
  purrr::walk(function(mapDF) {
    m <<- m %>%
      addCircleMarkers(data = stationList[[mapDF]],
                       lng=~Longitude, lat=~Latitude,
                       label = ~as.character(Station),
                     color = ~pal(Status),
                     radius = 6,
                     stroke = F, fillOpacity = 0.8,
                     labelOptions = labelOptions(noHide = T,
                                                 offset = ~c(offsetX, offsetY),
                                                 direction = "center",
                                                 textOnly = T,
                                                 textsize = "13px"))
  })

m %>%
  addLegend(pal = pal, values = ~Status, opacity = 1) %>%
  setView(lat = 38.06979067575653, lng = -121.84727645926255, zoom = 10) %>%
  mapshot(file = "slsMap.png", cliprect = "viewport",
          vwidth = 850, vheight = 500, zoom = 5)
```

![Map displaying the geographic range of work. Each point represents the location of a sampling station. Stations in the southern and central Delta (809-919) and at Barker Slough (716) have monitoring requirements tied to the 2020 SWP Incidental Take Permit (ITP) and are uniquely colored.](slsMap.png){width=600px}

**Number of sites:** `r length(unique(SLS$Station))` stations. See the [metadata section](#metadata) for additional details of each station.

**Data range:** `r min(SLS$Date)` to `r max(SLS$Date)` (YYYY-mm-dd) <br>

**Sampling frequency**: Sampling begins in December and is conducted *every other week*. Sampling ends:

1. in March,
2. or when catch efficiency decreases,
3. or when high densities of Longfin Smelt are no longer found in the southern and central Delta and in danger of being entrained at the CVP and SWP intakes.

## Field Sampling Methods

**Net:** The SLS samples using a cone shaped net with a length of 3.35 meters (m), a mouth area of 0.37 m$^2$, and a 505 $\mu$m NitexR mesh. The mesh size was altered prior to the 2014 season to 500 $\mu$m NitexR, when the original mesh size was no longer available and new nets were purchased (see 2014 changes below). These new nets were incorporated as old nets became unusable. The net is mounted on a fixed D-frame with skis and is connected to the frame by a canvas mouth. At the end of each tow, net contents are washed into a cod-end jar attached to the end of the net. A General Oceanics flowmeter is mounted across the net’s mouth to estimate the water volume filtered during each tow. Prior to 2015, all flowmeters were calibrated at UC Davis before the start of the season to determine its calibration factor required for water volume calculations. After 2015, the calibration flume at UC Davis became inoperable, and the meters were sent to General Oceanics for refurbishing before each field season and the factory calibration factor used. Since 2019, meters are inspected at the end of every field season and are replaced with new units if refurbishing is required to support the continued use of the factory calibration factor.

**Tow:** A single 10 minute stepped oblique tow with the boat moving at 1 m/s is conducted at each of the sampling stations. The amount of cable released is dependent on the water depth at the station. A gradual oblique tow is achieved following the tow schedule specific to the amount of cable released and the duration of the tow. Although most tows are 10 minutes in length, tow time can be reduced in the event of a of a clogged net. Periods of heavy samples may result due to algal blooms, jellyfish blooms, or heavy debris events. The tow time can be reduced to 5 or 2.5 minutes, an alternate tow schedule is followed, and the duration is recorded. If material is still overflowing from the cod-end jar in a 2.5 minute tow, the entire station is dropped. Re-tows can occur if a sample is compromised or the flowmeter reading is less than 10000 or greater than 30000 in a 10 minute tow. All abnormal events are to be recorded in the "comments" section of the datasheet.

**Environmental and water quality data:** Immediately prior to each tow, surface and benthic water quality data are independently collected including: 1) surface water temperature (°C), surface turbidity (FNU), surface and bottom EC ($\mu$S/cm, normalized at 25 °C) are recorded using a calibrated and rinsed YSI ProDSS; and 2) surface turbidity (NTU) is recorded using a calibrated HACH 2100p turbidimeter. Secchi depth (cm) is measured using Secchi discs mounted to rigid meter sticks to a maximum depth of two meters; values are measured in the shade without sunglasses on, off the side of the boat by the same person for the day for consistency. Water bottom depth (ft) is recorded using a depth finder on the boat. Tide data is recorded as the visually observed tidal stage by the crew during the tow as high slack, ebb, low slack, or flood.

```{r table of equipment used to measure abiotic data}
data.frame(Variable = c("Water temperature (surface)", 
                        "Water EC (surface)", 
                        "Water EC (bottom)",
                        "Water turbidity (surface)",
                        "Water turbidity (surface)",
                        "Secchi depth", 
                        "Flow meter", 
                        "Depth", 
                        "Tide"),
           Equipment = c("YSI ProDSS", 
                         "YSI ProDSS", 
                         "YSI ProDSS", 
                         "YSI ProDSS",
                         "HACH 2100p",
                         "Two meter sticks", 
                         "General Oceanics 2030R", 
                         "Onboard meter", 
                         "Visual"),
           Unit = c(paste0("\U00B0", "C"), 
                    paste0("\U00B5", "m/cm"),
                    paste0("\U00B5", "m/cm"),
                    "FNU", 
                    "NTU",
                    "cm", 
                    "", 
                    "Feet", 
                    "")) %>% 
  kbl(booktabs = T, linesep = "", caption = "The SLS collects various environmental data per station.") %>%
  kable_styling(latex_options = c("striped", "hold_position"))
```

**Catch data:** At the end of every tow, the net is washed down so that all visible vegetation, fish, sand, and debris are washed into the cod-end jar. Large debris and adult fish ($\ge$ 50 mm) can be removed if positively identified. If salmonids were caught, fork lengths are measured, presence or absence of the adipose fin noted, and the fish are immediately released gently and alive. All other larval and juvenile fish are kept in distinctively labeled sampling jars and preserved in 10% buffered and dyed formalin for later processing in the laboratory.

## Lab analysis, fish ID and QC

In the lab fish are identified from each sample under a microscope. First, fish are separated from debris and other organisms during a process referred to as "sorting". Then, the entire sample undergoes a quality control (QC) check to ensure that fish were not missed during sorting. Finally, fish undergo a first ID and count by an identifier, followed by a QC from a larval fish ID specialist to confirm all species identifications and counts. This QC process is dependent on the experience of the first identifier doing the first ID. Fish identifiers will begin with all their identifications QC'ed and transition to having fewer and fewer samples QC’ed with experience, until the identifier is considered a larval fish ID specialist. Once the larval fish ID specialist level is acquired, samples are randomly selected to undergo the QC process. Across all samples (QC required or not), all CESA and ESA fishes and any questionable fish IDs must undergo a second ID. All fish are identified to species or the lowest possible taxon. Only the first 50 randomly selected individuals of each species from each tow are measured for lengths to the nearest millimeter, and the rest of the sample is simply enumerated. However, all  Delta Smelt (*Hypomesus transpacificus*) are measured for lengths regardless of catch size. All Longfin Smelt are measured unless there is an excessive amount (>200) then only 100 are measured and the rest are plus counted. 

## Relative density analysis

The total number of fish per volume water sampled (standardized to 1000 $m^3$) is calculated using the following two equations:

<center>

$V_{t} = A * K * D_{t}$

</center>

*Where:*

$V_{t}$ = volume of water ($m^{3}$) filtered through the net per tow $t$

$A$ = mouth opening of the net (0.37 $m^{2}$)

$K$ = calibration factor of the flow meter, 0.026873027 since 2015

$D_{t}$ = difference in flow meter counts from start to finish of tow $t$

<center>
$n_{t} = F_{t}/V_{t} * 1000 m^{3}$
</center>

*Where:*

$n_{t}$ = number of fish per 1000 $m^{3}$ per tow $t$

$F_{t}$ = fish caught per tow $t$

$V_{t}$ = volume of water filtered through the net $m^{3}$ per tow $t$

## Data management

All data is entered into a digital Microsoft Access database once the fish id has been finalized. Immediately after entry, data undergoes two rounds of ‘line-by-line’ checks, wherein all data fields are checked against the original datasheets for fidelity. At the end of the SLS survey field season, once all the fish samples have been processed in the laboratory and data entry is complete, all data is ‘finalized’ to be as accurate as possible for public use. The first step in this process is to conduct two additional final line-by-lines checks. Next, a project lead will run a series of coded queries to analyze the underlying data distributions to detect potential outliers in the environmental data. Not all data is changed if it is flagged as an outlier (generally beyond 2 standard deviations of the mean). In most cases, outliers are real data. These queries simply alert the project lead of potential erroneous data, and care is taken to edit only data that truly needs to be edited, e.g., data that was entered incorrectly or caused by equipment failures. All resulting data edits are documented in a separate log file.

## The provided data tables

The “Catch.csv”, “FishCodes.csv”, “Length.csv”, “MeterCorrections.csv”, “Station_Lookup.csv”, “TowInfo.csv”, and “WaterInfo.csv” are available “relational tables” from the SLS Access database. These tables are exported directly from Access in R and the only manipulations were to include  relevant columns, fix Unicode encoding errors, and fix float formatting errors; all underlying data collected in the field and entered into the database remained unmanipulated. The “SLS.csv” file is the integrated dataset that combines 6 relational tables (the “FishCodes.csv” table” is not included) together. Users should be aware of the units of the recorded values between the relational and integrated tables, as they may differ (documented in the metadata section of the EDI publication page). All steps are coded in R and the relevant codes are provided with the EDI publication and/or housed on [trinhxuann/CDFW-IEP-Surveys GitHub page](https://github.com/trinhxuann/CDFW-IEP-Surveys).

### Zero filling

Zero filling is the process of assigning a count value of 0 for instances of no fish catch during a tow. No fish catch can be defined as two levels: 1) across all fish species (a tow that catches no fishes at all), or 2) specific to a singular species (a tow that catches no individuals of a particular species but does for other species). Instances of no fish catch of *any* fish species in a tow (level 1) *are not* recorded in the relational “Catch.csv” table, but the environmental data associated with that tow *is* recorded in the relational “TowInfo.csv” table. The joined "SLS.csv" table flagged these instances in the `Length_NA_flag` column and filled in the corresponding catch count value (`Count`) as 0. This zero-filling was not implemented for instances of no fish catch of a particular species in a tow (level 2) in the integrated "SLS.csv" file; however, code for this step is provided in the "SLSIntegrateEDI.R" script for users who are interested.

### Count data
The `Count` data provided is the adjusted length frequency of each recorded length per species per tow:

<center>
$F_{a,l} = T_{c}\bigg(\frac{F_{m,l}}{T_{m}}\bigg)$
</center>

*Where:*

$F_{a,l}$ = adjusted frequency of each recorded length $l$

$T_{c}$ = total catch

$F_{m,l}$ = measured frequency of each recorded length $l$

$T_{m}$ = total number of fish measured

\newpage

## Project history

The table below is a timeline of critical changes to the survey methods since its inception. The years listed below are water years, which begins three months before the new calendar year on October 1.

```{r history table, results='asis'}
df <- read.csv("yearlyChanges_SLS.csv")

pos <- df %>%
  mutate(rowIndex = row_number(waterYear)) %>%
  arrange(waterYear) %>%
  group_by(waterYear) %>%
  mutate(groupIndex = cur_group_id()) %>%
  filter(groupIndex %% 2 == 1) %>%
  pull(rowIndex)

df %>%
  rename("Water Year" = waterYear) %>% 
  kbl(booktabs = T, longtable = T, caption = "History of substantial changes to the SLS since its inception.") %>%
  row_spec(pos, background = "#EEEEEE") %>%
  column_spec(2, width = "40em")
```

\newpage

## Station metadata {#metadata}

Station theoretical latitudes and longitudes and start and end dates are provided in Table 2. A visualization of the number of surveys per water year (which encapsulates a field season) is also provided in Figure 2.

```{r, station metadata}
SLS %>% group_by(Station, Latitude, Longitude) %>%
    slice(1, n()) %>% select(Date, Station, Latitude, Longitude) %>%
    mutate(start = c("StartDate", "EndDate")) %>%
    ungroup() %>%
    tidyr::pivot_wider(names_from = "start", values_from = "Date") %>%
    # Going to just say that anything taken 30 days since the last date in the dataset == ongoing survey
    mutate(EndDate = if_else(EndDate >= as.Date(max(SLS$Date)) - 30, "Ongoing", as.character(EndDate))) %>%
    kbl(booktabs = T, longtable = T, caption = paste0("List of stations sampled by SLS since its inception. ", dQuote("StartDate"), " indicates the date when sampling first began for a station; ", dQuote("EndDate"), " indicates the date when sampling last ended at a station, and ", dQuote("Ongoing"), " represents stations that are still actively sampled by the survey."))
```

<!-- ```{r, station figure, fig.width=20, fig.height=18, fig.cap="The number of times a station was surveyed per water year is shown in various colors, following documentation present in Table 1. No color indicates that a station was not sampled for that water year."} -->
<!-- SLS %>% -->
<!--     distinct(waterYear = as.factor(as.numeric(format(as.Date(Date), "%Y")) + (as.numeric(format(as.Date(Date), "%m")) > 9)), -->
<!--              Station, Survey) %>% -->
<!--     group_by(waterYear, Station, Survey) %>% -->
<!--     count() %>% -->
<!--     group_by(waterYear, Station = as.character(Station)) %>% -->
<!--     summarise(numSurvey = sum(n)) %>% -->
<!--   { -->
<!--     ggplot(data = ., aes(waterYear, Station, fill = factor(numSurvey, levels = sort(unique(.$numSurvey))))) + -->
<!--       geom_tile(color = "black") + -->
<!--       scale_y_discrete(limits = rev) + -->
<!--       scale_fill_manual(values = c("#0073C2FF", "#EFC000FF", "#868686FF", "#CD534CFF", "#008A32")) + -->
<!--       labs(title = "Number of surveys per station per water year", -->
<!--            fill = "Number of surveys", -->
<!--            x = "Water Year") + -->
<!--       theme_classic(base_size = 35) + -->
<!--       theme(legend.position = "bottom") -->
<!--   } -->
<!-- ``` -->

<!-- \newpage -->

<!-- ```{r table of station figure 2} -->
<!-- SLS %>% -->
<!--     distinct(waterYear = as.factor(as.numeric(format(as.Date(Date), "%Y")) + (as.numeric(format(as.Date(Date), "%m")) > 9)), -->
<!--              Station, Survey) %>% -->
<!--     group_by(waterYear, Station, Survey) %>% -->
<!--     count() %>% -->
<!--     group_by(waterYear, Station) %>% -->
<!--     summarise(numSurvey = sum(n)) %>% -->
<!--   rename("Water Year" = waterYear, -->
<!--          "Number of Surveys" = "numSurvey") %>% -->
<!--   kbl(booktabs = T, longtable = T, caption = "Frequency of number of surveys at each station in the SLS Survey per water year since its inception in 2009.") %>% -->
<!--   kable_styling(latex_options = "repeat_header") -->

<!-- # This is the grayscale version that is 100% colorblind friendly and contrast-correct: -->
<!-- # LTMRdata::SLS %>% -->
<!-- #   distinct(waterYear = as.factor(as.numeric(format(Date, "%Y")) + (as.numeric(format(Date, "%m")) > 9)), -->
<!-- #            Station, Survey) %>% -->
<!-- #   group_by(waterYear, Station, Survey) %>% -->
<!-- #   count() %>% -->
<!-- #   group_by(waterYear, Station) %>% -->
<!-- #   mutate(numSurvey = sum(n)) %>% -->
<!-- #   { -->
<!-- #     ggplot(data = ., aes(waterYear, Station, fill = factor(numSurvey, levels = sort(unique(.$numSurvey))))) + -->
<!-- #       geom_tile(color = "grey50") + -->
<!-- #       geom_text(aes(label = numSurvey), color = "#FFFFFF", size = 5.5) + -->
<!-- #       scale_y_discrete(limits = rev) + -->
<!-- #           scale_fill_manual(values = c("#595959", "#383838", "#1F1F1F", "#000000")) + -->
<!-- #       labs(title = "Number of surveys per station per water year", -->
<!-- #            fill = "Number of surveys", -->
<!-- #            x = "Water Year") + -->
<!-- #       theme_classic(base_size = 24) + -->
<!-- #       theme(legend.position = "bottom") -->
<!-- #   } -->
<!-- ``` -->

\newpage

## Appendix

**Species Sampled:** 

```{r species sampled}
SLS %>% 
  filter(!Taxa %in% c(NA, "UnID")) %>% 
  group_by(Taxa) %>% 
  slice(1) %>% 
  transmute(CommonName, Taxa, DateFirstID = Date) %>% 
  arrange(CommonName, Taxa) %>% 
  kbl(booktabs = T, longtable = T, caption = "The SLS Survey identifies all captured fish. The date associated with the first identification of each species is provided. There has not been a taxa that is not identified by the survey if captured, although not all taxa are identified to the species level.")
```